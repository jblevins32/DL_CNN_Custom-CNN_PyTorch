{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIkt4yxKpzgS"
   },
   "source": [
    "# CS 7643 Assignment 2 Part 2:  Implement and train a network on CIFAR-10 using Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5eLeqVzpzgV"
   },
   "source": [
    "Convolutional Neural Networks (CNNs) are one of the major advancements in\n",
    "computer vision over the past decade. In this assignment, you will complete\n",
    "a simple CNN architecture from scratch and learn how to implement CNNs\n",
    "with PyTorch, one of the most commonly used deep learning frameworks.\n",
    "You will also run different experiments on imbalanced datasets to evaluate\n",
    "your model and techniques to deal with imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kx3nM2xMpzgW"
   },
   "source": [
    "# Setup Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l86tglWzpzgX"
   },
   "source": [
    "Before getting started we need to run some standard code to set up our environment. You'll need to execute this code again each time you start the notebook.\n",
    "\n",
    "First, run this cell to load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html?highlight=autoreload) extension. This enables us to modify `.py` source files and reintegrate them into the notebook, ensuring a smooth editing and debugging experience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "j22uun9OpzgX"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pOTy-9dpzgY"
   },
   "source": [
    "### Google Colab Setup\n",
    "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zujgqHl3pzgZ"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAQYM7TWpzgZ"
   },
   "source": [
    "Now remember the path in your Google Drive where you uploaded this notebook, fill it in below. If all functions properly, executing the next cell should display the filenames from the assignment:\n",
    "\n",
    "```\n",
    "['CS7643-Assignment2-2.ipynb', 'cs7643', 'checkpoints', 'losses', 'configs', 'models', 'tests']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UiGZhhG8pzga"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() argument must be str, bytes, or os.PathLike object, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# TODO: Fill in the Google Drive path where you uploaded assignment1\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Example: If you create a Fall2023 folder and put all the files under A1 folder, then 'Fall2023/A1'\u001b[39;00m\n\u001b[1;32m      5\u001b[0m GOOGLE_DRIVE_PATH_POST_MYDRIVE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m GOOGLE_DRIVE_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrive\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMyDrive\u001b[39m\u001b[38;5;124m'\u001b[39m, GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(GOOGLE_DRIVE_PATH))\n",
      "File \u001b[0;32m<frozen posixpath>:90\u001b[0m, in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n",
      "File \u001b[0;32m<frozen genericpath>:164\u001b[0m, in \u001b[0;36m_check_arg_types\u001b[0;34m(funcname, *args)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: join() argument must be str, bytes, or os.PathLike object, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# TODO: Fill in the Google Drive path where you uploaded assignment1\n",
    "# Example: If you create a Fall2023 folder and put all the files under A1 folder, then 'Fall2023/A1'\n",
    "GOOGLE_DRIVE_PATH_POST_MYDRIVE = None\n",
    "GOOGLE_DRIVE_PATH = os.path.join('/content', 'drive', 'MyDrive', GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n",
    "print(os.listdir(GOOGLE_DRIVE_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svKml_u_mwNn"
   },
   "source": [
    "### Local Setup or Google Colab\n",
    "Run the cell below regardless of setup to set the path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "itp51CmXmy03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    }
   ],
   "source": [
    "# if running locally set GOOGLE PATH\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "  print(f'Running in google colab. Our path is `{GOOGLE_DRIVE_PATH}`')\n",
    "else:\n",
    "  GOOGLE_DRIVE_PATH = '.'\n",
    "  print('Running locally.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C48GISpDpzga"
   },
   "source": [
    "After successfully mounting your Google Drive and identifying the path to this assignment, execute the following cell to enable us to import from the `.py` files of this assignment. If it works correctly, it should print the message (note, you may need to retry this twice if it fails):\n",
    "\n",
    "```\n",
    "Roger that from cnn.py!\n",
    "Roger that from my_model.py!\n",
    "Roger that from resnet.py!\n",
    "Roger that from twolayer.py!\n",
    "\n",
    "Roger that from focal_loss.py!\n",
    "```\n",
    "\n",
    "as well as the last edit time for the files `cnn.py`, `my_model.py`, `resnet.py`, `twolayer.py`, and `focal_loss.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QeqHoG1Dpzga"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'say_hello_do_you_copy' from 'cs7643.utils' (/home/jblevins32/DL_A2/part2-pytorch/cs7643/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m      4\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(GOOGLE_DRIVE_PATH)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcs7643\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menv_prob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m say_hello_do_you_copy\n\u001b[1;32m      8\u001b[0m say_hello_do_you_copy(GOOGLE_DRIVE_PATH)\n",
      "File \u001b[0;32m~/DL_A2/part2-pytorch/cs7643/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mnist, cifar10, submit, visiondataset, solver, env_prob\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download_and_extract_archive, check_integrity, say_hello_do_you_copy\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'say_hello_do_you_copy' from 'cs7643.utils' (/home/jblevins32/DL_A2/part2-pytorch/cs7643/utils.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "sys.path.append(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "from cs7643.env_prob import say_hello_do_you_copy\n",
    "\n",
    "say_hello_do_you_copy(GOOGLE_DRIVE_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rev2Ozk1KGj3"
   },
   "source": [
    "# Load the CIFAR10 dataset\n",
    "Data loading is the very first step of any machine learning pipelines. Run the following cell to download the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kHlccnRMKXTw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from cs7643.cifar10 import CIFAR10\n",
    "\n",
    "cifar10_ds = CIFAR10(GOOGLE_DRIVE_PATH + '/data/cifar10', download=True, train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pf2FgYgT3W03"
   },
   "source": [
    "We will use GPUs to accelerate our computation in this notebook. Run the following to make sure GPUs are enabled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kuHZ057d3Uwx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device = cpu\n",
      "WARNING: Using CPU will cause slower train times\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_available() else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device = \" + device)\n",
    "if device == 'cpu':\n",
    "    print(\"WARNING: Using CPU will cause slower train times\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tgfHDh0pzgb"
   },
   "source": [
    "# Training\n",
    "The first thing of working with PyTorch is to get yourself familiarized with\n",
    "the basic training step of PyTorch. Read through the [PyTorch Tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html) and complete __compute_loss_update_params_ function in `./solver.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuL2J65znk9R"
   },
   "source": [
    "## PyTorch Model\n",
    "You will now implement some actual networks with PyTorch. We provide\n",
    "some starter files for you in `./models`. The models for you to implement are\n",
    "as follows:\n",
    "\n",
    "* **Two-Layer Network**. This is the same network you have implemented from scratch in assignment 1. You will build the model with two fully connected layers and a sigmoid activation function in between the two layers. Please implement the model as instructed in `./models/twolayer.py`.\n",
    "\n",
    "* **Vanilla Convolutional Neural Network**. You will build the model with a\n",
    "convolution layer, a ReLU activation, a max-pooling layer, followed by a fully connected layer for classification. Your convolution layer should use **32 output channels**, a **kernel size of 7** with **stride 1** and **zero padding**. You max-pooling should use a **kernel size of 2** and **stride of 2**. The fully connected layer should have **10 output features**. Please implement the model as instructed in `./models/cnn.py`.\n",
    "\n",
    "* Your Own Network. You are now free to build your own model. Notice that it's okay for you to borrow some insights from existing well-known networks, however, directly using those networks as-is is **NOT** allowed.\n",
    "In other words, you have to build your model from scratch, which also means using any sort of pre-trained weights is also **NOT** allowed. Please implement your model in `./models/my_model.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgEN4027oF9j"
   },
   "source": [
    "We provide you configuration files for these three models respectively. For\n",
    "Two-Layer Network and Vanilla CNN, you need to train the model without modifying the configuration file. The script automatically saves the weights of the best model at the end of training. We will evaluate your implementation by loading your model weights and evaluating the model on CIFAR-10 test data. You should expect the accuracy of Two-Layer Network and Vanilla CNN to be around 0.3 and 0.4 respectively.\n",
    "\n",
    "For your own network, you are free to tune any hyper-parameters to\n",
    "obtain better accuracy. Your final accuracy must be above 0.5 to receive\n",
    "at least partial credit. Please refer to the GradeScope auto-test results\n",
    "for the requirement of full credits. Try to keep your submission **under\n",
    "100mb or GradeScope may not accept it**. All in all, please make sure\n",
    "the checkpoints of each model are saved into `./checkpoints`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbYkRflMMQR-"
   },
   "source": [
    "Select a configuration file from the dropdown list then run the cell to train your model. To select a custom config, select \"Show code\" and specify the path to your config file. **Note that you may have to restart the jupyter kernel after updating the files above before running the below snippet.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "form",
    "id": "G4HceY6Fy2vx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a model using configuration file ./configs/config_mymodel.yaml\n",
      "{'batch_size': 64, 'learning_rate': 0.005, 'reg': 0.0005, 'epochs': 15, 'steps': [6, 8], 'warmup': 0, 'momentum': 0.9, 'gamma': 1, 'model': 'MyModel', 'imbalance': 'regular', 'save_best': True, 'loss_type': 'CE', 'device': 'cpu', 'prefix_path': '.'}\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MyModel(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.01)\n",
      "    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (15): LeakyReLU(negative_slope=0.01)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (18): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): LeakyReLU(negative_slope=0.01)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (23): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (24): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (25): LeakyReLU(negative_slope=0.01)\n",
      "    (26): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (28): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (fully_connected): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch: [0][0/782]\tTime 1.032 (1.032)\tLoss 2.4142 (2.4142)\tPrec @1 0.2188 (0.2188)\t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(kwargs)\n\u001b[1;32m     24\u001b[0m solver \u001b[38;5;241m=\u001b[39m Solver(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 25\u001b[0m solver\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/DL_A2/part2-pytorch/solver.py:167\u001b[0m, in \u001b[0;36mSolver.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adjust_learning_rate(epoch)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# train loop\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_step(epoch)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# validation loop\u001b[39;00m\n\u001b[1;32m    170\u001b[0m acc, cm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(epoch)\n",
      "File \u001b[0;32m~/DL_A2/part2-pytorch/solver.py:202\u001b[0m, in \u001b[0;36mSolver._train_step\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    199\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    200\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 202\u001b[0m out, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_loss_update_params(data, target)\n\u001b[1;32m    204\u001b[0m batch_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_accuracy(out, target)\n\u001b[1;32m    206\u001b[0m losses\u001b[38;5;241m.\u001b[39mupdate(loss\u001b[38;5;241m.\u001b[39mitem(), out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/DL_A2/part2-pytorch/solver.py:307\u001b[0m, in \u001b[0;36mSolver._compute_loss_update_params\u001b[0;34m(self, data, target)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# Main backward pass to Update gradients\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 307\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m#############################################################################\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m#                              END OF YOUR CODE                             #\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m#############################################################################\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m#       HINT: torch.no_grad()                                               #\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m#############################################################################\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cs7643-a2/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    523\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/cs7643-a2/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m _engine_run_backward(\n\u001b[1;32m    290\u001b[0m     tensors,\n\u001b[1;32m    291\u001b[0m     grad_tensors_,\n\u001b[1;32m    292\u001b[0m     retain_graph,\n\u001b[1;32m    293\u001b[0m     create_graph,\n\u001b[1;32m    294\u001b[0m     inputs,\n\u001b[1;32m    295\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    296\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    297\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/cs7643-a2/lib/python3.12/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    770\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    771\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from solver import Solver\n",
    "\n",
    "# Change this line to choose model to train!!!\n",
    "config_file = \"config_mymodel\" # @param [\"config_mymodel\", \"config_twolayer\", \"config_vanilla_cnn\",\"config_resnet32\"]\n",
    "\n",
    "config_file = GOOGLE_DRIVE_PATH + \"/configs/\" + config_file + \".yaml\"\n",
    "\n",
    "print(\"Training a model using configuration file \" + config_file)\n",
    "\n",
    "with open(config_file, \"r\") as read_file:\n",
    "  config = yaml.safe_load(read_file)\n",
    "\n",
    "kwargs = {}\n",
    "for key in config:\n",
    "  for k, v in config[key].items():\n",
    "    if k != 'description':\n",
    "      kwargs[k] = v\n",
    "\n",
    "kwargs['device'] = device\n",
    "kwargs['prefix_path'] = GOOGLE_DRIVE_PATH\n",
    "\n",
    "print(kwargs)\n",
    "\n",
    "solver = Solver(**kwargs)\n",
    "solver.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D68rtzAZpzgc"
   },
   "source": [
    "# Data Wrangling\n",
    "So far we have worked with well-balanced datasets (samples of each class are\n",
    "evenly distributed). However, in practice, datasets are often not balanced.\n",
    "In this section, you will explore the limitation of standard training strategy\n",
    "on this type of dataset. This being an exploration, it is up to you to design\n",
    "experiments or tests to validate these methods are correct and effective.\n",
    "You will work with an unbalanced version of CIFAR-10 in this section, and you should use the ResNet-32 model in `./models/resnet.py`.\n",
    "\n",
    "## Class-Balanced Focal Loss\n",
    "You will implement one possible solution to the imbalance problem: ClassBalanced Focal Loss using this CVPR-19 paper [Class-Balanced Loss Based on Effective Number of Samples](https://arxiv.org/pdf/1901.05555.pdf). You may also refer to the original paper of [Focal Loss](https://arxiv.org/abs/1708.02002) for more details if you are interested. Please implement CB Focal\n",
    "Loss in `./losses/focal_loss.py`.\n",
    "\n",
    "**Note**: The CVPR-19 paper uses SigmoidÌ² CB focal loss (section 4). Softmax CB focal loss is not described in the paper, but it is easy to derive from the mentioned papers. You must implement the softmax version to pass the\n",
    "tests.\n",
    "\n",
    "Hint: Make sure you are using torch operations througout your focal loss implementation otherwise the torch computation graph will not be built properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "FUEYEuHBpzgd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107865.26s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.0, pytest-7.4.4, pluggy-1.0.0\n",
      "rootdir: /home/jblevins32/DL_A2/part2-pytorch\n",
      "plugins: launch-testing-1.0.6, ament-copyright-0.12.11, launch-testing-ros-0.19.7, ament-flake8-0.12.11, ament-lint-0.12.11, ament-xmllint-0.12.11, ament-pep257-0.12.11, anyio-4.2.0\n",
      "collected 2 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "tests/test_focalloss.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "tests/test_focalloss.py::TestFocalLoss::test_focal_loss_equals_ce_loss\n",
      "  Warning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m========================= \u001b[32m2 passed\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 1.21s\u001b[0m\u001b[33m =========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Test your Focal Loss implementation\n",
    "!pytest -s {GOOGLE_DRIVE_PATH + '/tests/test_focalloss.py'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, follow the instructions in the report template to obtain the best results possible for Resnet with regular CE loss (you may need to perform extra hyperparameter tuning). Then experiment with the beta parameter. Finally,  obtain the best possible results for Resnet using focal loss. You are welcome to change other hyperparameters in the config file as necessary. Make sure to set the `imbalance` config parameter as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zWfbgzB4Uiu"
   },
   "source": [
    "Let's test your models implementation. **Make sure to train your models and create checkpoints before running the following tests**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "Db0t0IChKK0h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107948.83s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.0, pytest-7.4.4, pluggy-1.0.0\n",
      "rootdir: /home/jblevins32/DL_A2/part2-pytorch\n",
      "plugins: launch-testing-1.0.6, ament-copyright-0.12.11, launch-testing-ros-0.19.7, ament-flake8-0.12.11, ament-lint-0.12.11, ament-xmllint-0.12.11, ament-pep257-0.12.11, anyio-4.2.0\n",
      "collected 1 item                                                               \u001b[0m\u001b[1m\n",
      "\n",
      "tests/test_twolayer.py Files already downloaded and verified\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "tests/test_twolayer.py::TestTwoLayer::test_accuracy\n",
      "tests/test_twolayer.py::TestTwoLayer::test_accuracy\n",
      "  Warning: This process (pid=355150) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m======================== \u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m2 warnings\u001b[0m\u001b[33m in 4.72s\u001b[0m\u001b[33m =========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Let's test your implementation of two layer\n",
    "!pytest -s {GOOGLE_DRIVE_PATH + '/tests/test_twolayer.py'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "X97MN9JvcMQY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32498.76s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.0, pytest-7.4.4, pluggy-1.0.0\n",
      "rootdir: /home/jblevins32/DL_A2/part2-pytorch\n",
      "plugins: launch-testing-1.0.6, ament-copyright-0.12.11, launch-testing-ros-0.19.7, ament-flake8-0.12.11, ament-lint-0.12.11, ament-xmllint-0.12.11, ament-pep257-0.12.11, anyio-4.2.0\n",
      "collected 3 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "tests/test_mymodel.py Files already downloaded and verified\n",
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "tests/test_mymodel.py::TestMyModel::test_accuracy_easy\n",
      "tests/test_mymodel.py::TestMyModel::test_accuracy_easy\n",
      "  Warning: This process (pid=298020) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m======================== \u001b[32m3 passed\u001b[0m, \u001b[33m\u001b[1m2 warnings\u001b[0m\u001b[33m in 32.00s\u001b[0m\u001b[33m ========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Let's test your implementation of my_model\n",
    "!pytest -s { GOOGLE_DRIVE_PATH + '/tests/test_mymodel.py'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "zaXbxcApKPNw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32482.76s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.0, pytest-7.4.4, pluggy-1.0.0\n",
      "rootdir: /home/jblevins32/DL_A2/part2-pytorch\n",
      "plugins: launch-testing-1.0.6, ament-copyright-0.12.11, launch-testing-ros-0.19.7, ament-flake8-0.12.11, ament-lint-0.12.11, ament-xmllint-0.12.11, ament-pep257-0.12.11, anyio-4.2.0\n",
      "collected 1 item                                                               \u001b[0m\u001b[1m\n",
      "\n",
      "tests/test_vanilla_cnn.py Files already downloaded and verified\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "tests/test_vanilla_cnn.py::TestVanillaCNN::test_accuracy\n",
      "tests/test_vanilla_cnn.py::TestVanillaCNN::test_accuracy\n",
      "  Warning: This process (pid=297968) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m======================== \u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m2 warnings\u001b[0m\u001b[33m in 6.29s\u001b[0m\u001b[33m =========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Let's test your implementation of Vanilla CNN\n",
    "!pytest -s {GOOGLE_DRIVE_PATH + '/tests/test_vanilla_cnn.py'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjZK5lqLFsor"
   },
   "source": [
    "# Submit Your Work\n",
    "After completing the notebook for this assignment (`assignment2_2.ipynb`), run the following cell to create a `.zip` file for you to download and then upload to Gradescope.\n",
    "\n",
    "**Please MANUALLY SAVE `*.py` files before executing the following cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "uPREUKv7FwPS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing zip file to:  ./assignment_2_2_submission.zip\n"
     ]
    }
   ],
   "source": [
    "from cs7643.submit import make_a2_2_submission\n",
    "\n",
    "make_a2_2_submission(GOOGLE_DRIVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
