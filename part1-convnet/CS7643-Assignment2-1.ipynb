{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIkt4yxKpzgS"
   },
   "source": [
    "# CS 7643 Assignment 2 Part 1:  Implement and train a network on CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5eLeqVzpzgV"
   },
   "source": [
    "Convolutional Neural Networks (CNNs) are one of the major advancements in\n",
    "computer vision over the past decade. In this assignment, you will complete\n",
    "a simple CNN architecture from scratch and learn how to implement CNNs\n",
    "with PyTorch, one of the most commonly used deep learning frameworks.\n",
    "You will also run different experiments on imbalanced datasets to evaluate\n",
    "your model and techniques to deal with imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kx3nM2xMpzgW"
   },
   "source": [
    "### Load Extensions\n",
    "Before getting started we need to run some standard code to set up our environment. You'll need to execute this code again each time you start the notebook.\n",
    "\n",
    "First, run this cell to load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html?highlight=autoreload) extension. This enables us to modify `.py` source files and reintegrate them into the notebook, ensuring a smooth editing and debugging experience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "j22uun9OpzgX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pOTy-9dpzgY"
   },
   "source": [
    "### Google Colab Setup\n",
    "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zujgqHl3pzgZ"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAQYM7TWpzgZ"
   },
   "source": [
    "Now remember the path in your Google Drive where you uploaded this notebook, fill it in below. If all functions properly, executing the next cell should display the filenames from the assignment:\n",
    "\n",
    "```\n",
    "['CS7643-Assignment2-1.ipynb', 'cs7643', 'data', 'configs', 'models', 'optimizer', 'tests']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UiGZhhG8pzga"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() argument must be str, bytes, or os.PathLike object, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# TODO: Fill in the Google Drive path where you uploaded assignment1\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Example: If you create a Fall2023 folder and put all the files under A1 folder, then 'Fall2023/A1'\u001b[39;00m\n\u001b[1;32m      5\u001b[0m GOOGLE_DRIVE_PATH_POST_MYDRIVE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m GOOGLE_DRIVE_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrive\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMyDrive\u001b[39m\u001b[38;5;124m'\u001b[39m, GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(GOOGLE_DRIVE_PATH))\n",
      "File \u001b[0;32m<frozen posixpath>:90\u001b[0m, in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n",
      "File \u001b[0;32m<frozen genericpath>:164\u001b[0m, in \u001b[0;36m_check_arg_types\u001b[0;34m(funcname, *args)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: join() argument must be str, bytes, or os.PathLike object, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# TODO: Fill in the Google Drive path where you uploaded assignment1\n",
    "# Example: If you create a Fall2023 folder and put all the files under A1 folder, then 'Fall2023/A1'\n",
    "GOOGLE_DRIVE_PATH_POST_MYDRIVE = None\n",
    "GOOGLE_DRIVE_PATH = os.path.join('/content', 'drive', 'MyDrive', GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n",
    "print(os.listdir(GOOGLE_DRIVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QeqHoG1Dpzga"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GOOGLE_DRIVE_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(GOOGLE_DRIVE_PATH)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GOOGLE_DRIVE_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(GOOGLE_DRIVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJAHYCutjXA4"
   },
   "source": [
    "### Local Setup OR Google Drive\n",
    "Run the cell below regardless of whether you are using google drive or local setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "N0TK4ozDjX8B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    }
   ],
   "source": [
    "# if running locally set GOOGLE PATH\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "  print(f'Running in google colab. Our path is `{GOOGLE_DRIVE_PATH}`')\n",
    "else:\n",
    "  GOOGLE_DRIVE_PATH = '.'\n",
    "  print('Running locally.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C48GISpDpzga"
   },
   "source": [
    "After successfully identifying the path to this assignment, execute the following cell to enable us to import from the `.py` files of this assignment. If it works correctly, it should print the message:\n",
    "\n",
    "```\n",
    "Roger that from conv_classifier.py!\n",
    "Roger that from softmax_ce.py!\n",
    "Roger that from linear.py!\n",
    "Roger that from relu.py!\n",
    "Roger that from max_pool.py!\n",
    "Roger that from convolution.py!\n",
    "\n",
    "Roger that from _base_optimizer.py!\n",
    "Roger that from sgd.py!\n",
    "```\n",
    "\n",
    "as well as the last edit time for the files `_conv_classifier.py`, `convolution.py`, `linear.py`, `max_pool.py`, `relu.py`, `softmax_ce.py`, `_base_optimizer.py`, and `sgd.py`. You may have to try running the cell twice if the first time fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "QeqHoG1Dpzga"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Modules ------------------\n",
      "Roger that from conv_classifier.py!\n",
      "Roger that from softmax_ce.py!\n",
      "Roger that from linear.py!\n",
      "Roger that from relu.py!\n",
      "Roger that from max_pool.py!\n",
      "Roger that from convolution.py!\n",
      "conv_classifier.py last edited on Thu Sep 26 21:02:33 2024\n",
      "softmax_ce.py last edited on Tue Aug 20 22:54:45 2024\n",
      "linear.py last edited on Thu Sep 26 21:31:16 2024\n",
      "relu.py last edited on Wed Sep 25 15:35:32 2024\n",
      "max_pool.py last edited on Thu Sep 26 17:56:49 2024\n",
      "convolution.py last edited on Thu Sep 26 19:52:36 2024\n",
      "\n",
      "---------- Optimizer ------------------\n",
      "Roger that from _base_optimizer.py!\n",
      "Roger that from sgd.py!\n",
      "_base_optimizer.py last edited on Tue Aug 20 22:54:45 2024\n",
      "sgd.py last edited on Fri Sep 27 12:18:09 2024\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from cs7643.env_prob import say_hello_do_you_copy\n",
    "\n",
    "say_hello_do_you_copy(GOOGLE_DRIVE_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9bM0Yujpzga"
   },
   "source": [
    "# Load the CIFAR10 dataset\n",
    "Data loading is the very first step of any machine learning pipelines. Run the following cell to download the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LrhqVZ9jpzgb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from cs7643.cifar10 import CIFAR10\n",
    "\n",
    "train_ds = CIFAR10(GOOGLE_DRIVE_PATH + '/data/cifar10', download=True, train=True)\n",
    "test_ds = CIFAR10(GOOGLE_DRIVE_PATH + '/data/cifar10', download=True, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tgfHDh0pzgb"
   },
   "source": [
    "# Implementing CNN from Scratch\n",
    "You will work in `./part1-convnet` for this part of the assignment. **Note that\n",
    "vectorization is not a requirement for this part of the assignment**.\n",
    "\n",
    "## Module Implementation\n",
    "You will now learn how to build CNN from scratch. Typically, a convolutional\n",
    "neural network is composed of several different modules and these modules\n",
    "work together to make the network effective. For each module, you will\n",
    "implement a forward pass (computing forwarding results) and a backward\n",
    "pass (computing gradients). Therefore, your tasks are as follows:\n",
    "\n",
    "Follow the instructions in the code to complete each module in `./modules`. Specifically, modules to be implemented are 2D convolution, 2D\n",
    "Max Pooling, ReLU, and Linear. These will be the building blocks of\n",
    "the full network. The file `./modules/conv_classifier.py` ties each of the\n",
    "aforementioned modules together and is the subject of the next section. Run the following cells to test your implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "X97MN9JvcMQY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.0, pytest-7.4.4, pluggy-1.0.0\n",
      "rootdir: /home/jblevins32/DL_A2/part1-convnet\n",
      "plugins: launch-testing-1.0.6, ament-copyright-0.12.11, launch-testing-ros-0.19.7, ament-flake8-0.12.11, ament-lint-0.12.11, ament-xmllint-0.12.11, ament-pep257-0.12.11, anyio-4.2.0\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "tests/test_linear.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.13s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Let's test your implementation of Linear\n",
    "!pytest -s {GOOGLE_DRIVE_PATH.replace(' ', '\\ ') + '/tests/test_linear.py'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "5PSgh7FpKERP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112863.32s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.0, pytest-7.4.4, pluggy-1.0.0\n",
      "rootdir: /home/jblevins32/DL_A2/part1-convnet\n",
      "plugins: launch-testing-1.0.6, ament-copyright-0.12.11, launch-testing-ros-0.19.7, ament-flake8-0.12.11, ament-lint-0.12.11, ament-xmllint-0.12.11, ament-pep257-0.12.11, anyio-4.2.0\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "tests/test_maxpool.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.45s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Let's test your implementation of Max Pooling\n",
    "!pytest -s {GOOGLE_DRIVE_PATH.replace(' ', '\\ ') + '/tests/test_maxpool.py'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Db0t0IChKK0h"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112871.85s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.0, pytest-7.4.4, pluggy-1.0.0\n",
      "rootdir: /home/jblevins32/DL_A2/part1-convnet\n",
      "plugins: launch-testing-1.0.6, ament-copyright-0.12.11, launch-testing-ros-0.19.7, ament-flake8-0.12.11, ament-lint-0.12.11, ament-xmllint-0.12.11, ament-pep257-0.12.11, anyio-4.2.0\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "tests/test_relu.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.09s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Let's test your implementation of RELU\n",
    "!pytest -s {GOOGLE_DRIVE_PATH.replace(' ', '\\ ') + '/tests/test_relu.py'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "zaXbxcApKPNw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119474.55s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.0, pytest-7.4.4, pluggy-1.0.0\n",
      "rootdir: /home/jblevins32/DL_A2/part1-convnet\n",
      "plugins: launch-testing-1.0.6, ament-copyright-0.12.11, launch-testing-ros-0.19.7, ament-flake8-0.12.11, ament-lint-0.12.11, ament-xmllint-0.12.11, ament-pep257-0.12.11, anyio-4.2.0\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "tests/test_conv.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.79s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Let's test your implementation of Conv2D\n",
    "!pytest -s {GOOGLE_DRIVE_PATH.replace(' ', '\\ ') + '/tests/test_conv.py'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D68rtzAZpzgc"
   },
   "source": [
    "## Network Implementation\n",
    "After finishing each module, it's time to put things together to form a real\n",
    "convolutional neural network.\n",
    "\n",
    "Follow the instructions in the code to complete a CNN network in `./modules/conv_classifier.py`. The network is constructed by a list of module definitions in order and should handle both forward and backward communication between modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vr0bG_Ecpzgd"
   },
   "source": [
    "# Optimizer\n",
    "You have implemented a simple SGD optimizer in assignment-1. In practice, it is common to use a momentum term in SGD for better convergence. Specifically, we introduce a new velocity term $v_t$ and the update rule is as follows:\n",
    "\n",
    "$$\n",
    "v_t = \\beta v_{t-1} - \\eta \\frac{\\partial L}{\\partial w} \\\\\n",
    "w = w + v_t\n",
    "$$\n",
    "\n",
    "where $\\beta$ denotes the momentum coefficient and $\\eta$ denotes the learning rate.\n",
    "\n",
    "Follow the instructions in the code to complete SGD with momentum\n",
    "in `./optimizer/sgd.py`. **Hint**: you will need to store and use the velocity\n",
    "from the previous iteration of SGD to compute the new gradient for\n",
    "the current iteration. Feel free to add member variable(s) to achieve\n",
    "this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "FUEYEuHBpzgd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.0, pytest-7.4.4, pluggy-1.0.0\n",
      "rootdir: /home/jblevins32/DL_A2/part1-convnet\n",
      "plugins: launch-testing-1.0.6, ament-copyright-0.12.11, launch-testing-ros-0.19.7, ament-flake8-0.12.11, ament-lint-0.12.11, ament-xmllint-0.12.11, ament-pep257-0.12.11, anyio-4.2.0\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "tests/test_sgd.py \u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.09s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Test your SGD implementation\n",
    "!pytest -s {GOOGLE_DRIVE_PATH.replace(' ', '\\ ') + '/tests/test_sgd.py'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P77ODmqHpzgd"
   },
   "source": [
    "# Experiments\n",
    "Now, you have completed coding the entire training process. Itâ€™s time to play with your model a little. If you're already attempted to train your implementation, you might have noticed that it is extremely slow. Therefore, we only want to deliberately overfit the model with a small portion of data to verify whether the model is learning something or not.\n",
    "\n",
    "You will train a small CNN with only 50 samples in CIFAR-10 dataset. The script will make a plot on the training data only and **be sure to include the plot in your report**. Your final accuracy should be slightly under `0.9` with the given network in the script. To start the training, execute the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OXlEUeySNIoq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples 49000\n",
      "Finished epoch 0 / 10: cost 2.322220, train: 0.120000, lr 1.000000e-04\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m SGD(model, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, reg\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[1;32m     21\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Solver()\n\u001b[0;32m---> 23\u001b[0m loss_history, train_acc_history \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m     24\u001b[0m     X_train[:\u001b[38;5;241m50\u001b[39m], y_train[:\u001b[38;5;241m50\u001b[39m], model, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     25\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, optimizer\u001b[38;5;241m=\u001b[39moptimizer\n\u001b[1;32m     26\u001b[0m     )\n\u001b[1;32m     28\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(train_acc_history)\n\u001b[1;32m     29\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m], loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupper left\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/DL_A2/part1-convnet/cs7643/solver.py:86\u001b[0m, in \u001b[0;36mSolver.train\u001b[0;34m(self, X, y, model, learning_rate_decay, sample_batches, num_epochs, batch_size, acc_frequency, verbose, optimizer)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# evaluate cost and gradient\u001b[39;00m\n\u001b[1;32m     85\u001b[0m out, cost \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(X_batch, y_batch)\n\u001b[0;32m---> 86\u001b[0m model\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     87\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mupdate(model)\n\u001b[1;32m     88\u001b[0m loss_history\u001b[38;5;241m.\u001b[39mappend(cost)\n",
      "File \u001b[0;32m~/DL_A2/part1-convnet/modules/conv_classifier.py:117\u001b[0m, in \u001b[0;36mConvNet.backward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Backward pass through each module in reverse order\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules):\n\u001b[0;32m--> 117\u001b[0m     module\u001b[38;5;241m.\u001b[39mbackward(dout)\n\u001b[1;32m    118\u001b[0m     dout \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mdx\n",
      "File \u001b[0;32m~/DL_A2/part1-convnet/modules/convolution.py:162\u001b[0m, in \u001b[0;36mConv2D.backward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdw[CO_iter, CI_iter] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m receptive_field \u001b[38;5;241m*\u001b[39m dout[N_iter, CO_iter, H_iter, W_iter] \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;66;03m# Compute input gradients\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdx[N_iter, CI_iter, h_start:h_end, w_start:w_end] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dout[N_iter, CO_iter, H_iter, W_iter] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight[CO_iter, CI_iter]\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# Compute bias gradients            \u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb[CO_iter] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(dout[N_iter,CO_iter,:,:])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from modules import ConvNet\n",
    "from optimizer import SGD\n",
    "from cs7643.solver import Solver\n",
    "from data import get_CIFAR10_data\n",
    "\n",
    "root = GOOGLE_DRIVE_PATH + '/data/cifar10/cifar-10-batches-py'\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data(root)\n",
    "\n",
    "print(f'Number of training samples {len(X_train)}')\n",
    "\n",
    "model_list = [dict(type='Conv2D', in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=1),\n",
    "              dict(type='ReLU'),\n",
    "              dict(type='MaxPooling', kernel_size=2, stride=2),\n",
    "              dict(type='Linear', in_dim=7200, out_dim=10)]\n",
    "criterion = dict(type='SoftmaxCrossEntropy')\n",
    "model = ConvNet(model_list, criterion)\n",
    "optimizer = SGD(model, learning_rate=0.0001, reg=0.001, momentum=0.9)\n",
    "\n",
    "trainer = Solver()\n",
    "\n",
    "loss_history, train_acc_history = trainer.train(\n",
    "    X_train[:50], y_train[:50], model, batch_size=10, num_epochs=10,\n",
    "    verbose=True, optimizer=optimizer\n",
    "    )\n",
    "\n",
    "plt.plot(train_acc_history)\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig(GOOGLE_DRIVE_PATH + '/train.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjZK5lqLFsor"
   },
   "source": [
    "# Submit Your Work\n",
    "After completing the notebook for this assignment (`assignment2_1.ipynb`), run the following cell to create a `.zip` file for you to download and to upload to Gradescope.\n",
    "\n",
    "**Please MANUALLY SAVE `*.py` files before executing the following cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "uPREUKv7FwPS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing zip file to:  ./assignment_2_1_submission.zip\n"
     ]
    }
   ],
   "source": [
    "from cs7643.submit import make_a2_1_submission\n",
    "\n",
    "make_a2_1_submission(GOOGLE_DRIVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
